{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 완료\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as p\n",
    "#path = \"C:/Users/Black/PycharmProjects/deeplearning/dataset\"\n",
    "# C:\\Users\\urse\\Desktop\\동작구\\동작구 빅데이터 공모전\\최종\\work\n",
    "path = \"C:/Users/urse/desktop/동작구/동작구 빅데이터 공모전/최종/work\"\n",
    "os.chdir(path)\n",
    "\n",
    "#train1 = pd.read_csv('sell_오만_150.csv', engine='python')\n",
    "train2 = pd.read_csv('sell_십만_150.csv', engine='python')\n",
    "#train3 = pd.read_csv('sell_오만_250.csv', engine='python')\n",
    "#train4 = pd.read_csv('sell_십만_250.csv', engine='python')\n",
    "\n",
    "# print(train1.shape, train2.shape, train3.shape, train4.shape)\n",
    "# print(train1.shape, train2.shape, train3.shape, train4.shape)\n",
    "#hump = pd.read_csv('동작구_험프_위치정보_(UTM_K).csv', engine='python')\n",
    "print('loading 완료')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  (38649, 14) (38649, 1)\n",
      "test :  (9663, 14) (9663, 1)\n",
      "Train on 30919 samples, validate on 7730 samples\n",
      "Epoch 1/1000\n",
      "30919/30919 [==============================] - 5s 170us/step - loss: 2.0511 - mae: 0.7240 - acc: 0.5453 - f1_m: 0.2216 - precision_m: 196636.5000 - recall_m: 0.2962 - val_loss: 0.1588 - val_mae: 0.2388 - val_acc: 0.7842 - val_f1_m: 0.1791 - val_precision_m: 868666.0000 - val_recall_m: 0.1134\n",
      "Epoch 2/1000\n",
      "30919/30919 [==============================] - 4s 145us/step - loss: 0.1771 - mae: 0.2838 - acc: 0.7210 - f1_m: 0.2559 - precision_m: 369987.0625 - recall_m: 0.2411 - val_loss: 0.1448 - val_mae: 0.2448 - val_acc: 0.7777 - val_f1_m: 0.2334 - val_precision_m: 620475.6875 - val_recall_m: 0.1733\n",
      "Epoch 3/1000\n",
      "30919/30919 [==============================] - 4s 142us/step - loss: 0.1336 - mae: 0.2430 - acc: 0.7612 - f1_m: 0.2800 - precision_m: 447606.7188 - recall_m: 0.2371 - val_loss: 0.1277 - val_mae: 0.2256 - val_acc: 0.7657 - val_f1_m: 0.2707 - val_precision_m: 372285.4062 - val_recall_m: 0.2252\n",
      "Epoch 4/1000\n",
      "30919/30919 [==============================] - 4s 145us/step - loss: 0.1271 - mae: 0.2353 - acc: 0.7632 - f1_m: 0.2863 - precision_m: 380336.3438 - recall_m: 0.2435 - val_loss: 0.1242 - val_mae: 0.2301 - val_acc: 0.7376 - val_f1_m: 0.3118 - val_precision_m: 175801.4844 - val_recall_m: 0.2924\n",
      "Epoch 5/1000\n",
      "30919/30919 [==============================] - 5s 154us/step - loss: 0.1226 - mae: 0.2295 - acc: 0.7650 - f1_m: 0.3013 - precision_m: 369987.0625 - recall_m: 0.2590 - val_loss: 0.1286 - val_mae: 0.2605 - val_acc: 0.7217 - val_f1_m: 0.3591 - val_precision_m: 186142.7500 - val_recall_m: 0.3553\n",
      "Epoch 6/1000\n",
      "30919/30919 [==============================] - 5s 147us/step - loss: 0.1193 - mae: 0.2259 - acc: 0.7643 - f1_m: 0.3027 - precision_m: 297542.0312 - recall_m: 0.2626 - val_loss: 0.1133 - val_mae: 0.2158 - val_acc: 0.7563 - val_f1_m: 0.3183 - val_precision_m: 237849.0625 - val_recall_m: 0.2823\n",
      "Epoch 7/1000\n",
      "30919/30919 [==============================] - 5s 146us/step - loss: 0.1172 - mae: 0.2230 - acc: 0.7668 - f1_m: 0.2997 - precision_m: 297542.0312 - recall_m: 0.2593 - val_loss: 0.1165 - val_mae: 0.2088 - val_acc: 0.7744 - val_f1_m: 0.2626 - val_precision_m: 361944.1562 - val_recall_m: 0.2151\n",
      "Epoch 8/1000\n",
      "30919/30919 [==============================] - 4s 143us/step - loss: 0.1157 - mae: 0.2203 - acc: 0.7668 - f1_m: 0.3113 - precision_m: 292367.4062 - recall_m: 0.2714 - val_loss: 0.1158 - val_mae: 0.2165 - val_acc: 0.7542 - val_f1_m: 0.3090 - val_precision_m: 165460.2344 - val_recall_m: 0.2804\n",
      "Epoch 9/1000\n",
      "30919/30919 [==============================] - 5s 156us/step - loss: 0.1143 - mae: 0.2189 - acc: 0.7666 - f1_m: 0.3175 - precision_m: 261319.5469 - recall_m: 0.2788 - val_loss: 0.1159 - val_mae: 0.2067 - val_acc: 0.7823 - val_f1_m: 0.2549 - val_precision_m: 372285.4062 - val_recall_m: 0.2062\n",
      "Epoch 10/1000\n",
      "30919/30919 [==============================] - 4s 137us/step - loss: 0.1133 - mae: 0.2171 - acc: 0.7665 - f1_m: 0.3125 - precision_m: 333764.5625 - recall_m: 0.2722 - val_loss: 0.1094 - val_mae: 0.2315 - val_acc: 0.7532 - val_f1_m: 0.3668 - val_precision_m: 258531.5781 - val_recall_m: 0.3348\n",
      "Epoch 11/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.1128 - mae: 0.2165 - acc: 0.7655 - f1_m: 0.3113 - precision_m: 258732.2188 - recall_m: 0.2768 - val_loss: 0.1089 - val_mae: 0.2101 - val_acc: 0.7719 - val_f1_m: 0.2979 - val_precision_m: 289555.3125 - val_recall_m: 0.2571\n",
      "Epoch 12/1000\n",
      "30919/30919 [==============================] - 4s 139us/step - loss: 0.1120 - mae: 0.2158 - acc: 0.7666 - f1_m: 0.3159 - precision_m: 284605.4375 - recall_m: 0.2751 - val_loss: 0.1190 - val_mae: 0.2193 - val_acc: 0.7286 - val_f1_m: 0.3783 - val_precision_m: 155119.0000 - val_recall_m: 0.3718\n",
      "Epoch 13/1000\n",
      "30919/30919 [==============================] - 4s 138us/step - loss: 0.1112 - mae: 0.2147 - acc: 0.7663 - f1_m: 0.3305 - precision_m: 279430.7812 - recall_m: 0.2908 - val_loss: 0.1098 - val_mae: 0.2251 - val_acc: 0.7583 - val_f1_m: 0.3526 - val_precision_m: 227507.7812 - val_recall_m: 0.3163\n",
      "Epoch 14/1000\n",
      "30919/30919 [==============================] - 5s 147us/step - loss: 0.1107 - mae: 0.2150 - acc: 0.7686 - f1_m: 0.3317 - precision_m: 292367.4062 - recall_m: 0.2909 - val_loss: 0.1194 - val_mae: 0.2282 - val_acc: 0.7283 - val_f1_m: 0.3805 - val_precision_m: 196484.0156 - val_recall_m: 0.3743\n",
      "Epoch 15/1000\n",
      "30919/30919 [==============================] - 5s 170us/step - loss: 0.1098 - mae: 0.2138 - acc: 0.7680 - f1_m: 0.3309 - precision_m: 274256.1562 - recall_m: 0.2884 - val_loss: 0.1170 - val_mae: 0.2402 - val_acc: 0.7422 - val_f1_m: 0.3958 - val_precision_m: 206825.2656 - val_recall_m: 0.3720\n",
      "Epoch 16/1000\n",
      "30919/30919 [==============================] - 5s 155us/step - loss: 0.1094 - mae: 0.2135 - acc: 0.7673 - f1_m: 0.3280 - precision_m: 271668.8438 - recall_m: 0.2883 - val_loss: 0.1101 - val_mae: 0.2356 - val_acc: 0.7730 - val_f1_m: 0.3249 - val_precision_m: 475698.0312 - val_recall_m: 0.2707\n",
      "Epoch 17/1000\n",
      "30919/30919 [==============================] - 5s 153us/step - loss: 0.1085 - mae: 0.2130 - acc: 0.7678 - f1_m: 0.3339 - precision_m: 294954.7188 - recall_m: 0.2920 - val_loss: 0.1031 - val_mae: 0.2092 - val_acc: 0.7779 - val_f1_m: 0.3036 - val_precision_m: 392967.9688 - val_recall_m: 0.2508\n",
      "Epoch 18/1000\n",
      "30919/30919 [==============================] - 5s 151us/step - loss: 0.1084 - mae: 0.2125 - acc: 0.7675 - f1_m: 0.3353 - precision_m: 269081.5000 - recall_m: 0.2940 - val_loss: 0.1108 - val_mae: 0.2243 - val_acc: 0.7679 - val_f1_m: 0.3112 - val_precision_m: 279214.0625 - val_recall_m: 0.27085 - acc: 0.7676 - f1_m: 0.3360 - precision_m: 265440.2188 - recall_m: 0.\n",
      "Epoch 19/1000\n",
      "30919/30919 [==============================] - 5s 165us/step - loss: 0.1083 - mae: 0.2119 - acc: 0.7673 - f1_m: 0.3315 - precision_m: 263906.8438 - recall_m: 0.2911 - val_loss: 0.1051 - val_mae: 0.2181 - val_acc: 0.7660 - val_f1_m: 0.3350 - val_precision_m: 217166.5312 - val_recall_m: 0.2958\n",
      "Epoch 20/1000\n",
      "30919/30919 [==============================] - 5s 166us/step - loss: 0.1075 - mae: 0.2113 - acc: 0.7688 - f1_m: 0.3391 - precision_m: 307891.3438 - recall_m: 0.2950 - val_loss: 0.1106 - val_mae: 0.2304 - val_acc: 0.7493 - val_f1_m: 0.3670 - val_precision_m: 196484.1094 - val_recall_m: 0.3453\n",
      "Epoch 21/1000\n",
      "30919/30919 [==============================] - 6s 199us/step - loss: 0.1074 - mae: 0.2115 - acc: 0.7687 - f1_m: 0.3378 - precision_m: 266494.1875 - recall_m: 0.2957 - val_loss: 0.1126 - val_mae: 0.2000 - val_acc: 0.7836 - val_f1_m: 0.2641 - val_precision_m: 372285.4375 - val_recall_m: 0.2115\n",
      "Epoch 22/1000\n",
      "30919/30919 [==============================] - 6s 194us/step - loss: 0.1069 - mae: 0.2104 - acc: 0.7684 - f1_m: 0.3433 - precision_m: 310478.6562 - recall_m: 0.3020 - val_loss: 0.1238 - val_mae: 0.2527 - val_acc: 0.7312 - val_f1_m: 0.4204 - val_precision_m: 165460.2500 - val_recall_m: 0.4131\n",
      "Epoch 23/1000\n",
      "30919/30919 [==============================] - 6s 196us/step - loss: 0.1065 - mae: 0.2096 - acc: 0.7684 - f1_m: 0.3427 - precision_m: 274256.1562 - recall_m: 0.3031 - val_loss: 0.1053 - val_mae: 0.2181 - val_acc: 0.7670 - val_f1_m: 0.3554 - val_precision_m: 279214.0625 - val_recall_m: 0.3102\n",
      "Epoch 24/1000\n",
      "30919/30919 [==============================] - 7s 225us/step - loss: 0.1064 - mae: 0.2101 - acc: 0.7692 - f1_m: 0.3374 - precision_m: 258732.2188 - recall_m: 0.2973 - val_loss: 0.1198 - val_mae: 0.2467 - val_acc: 0.7186 - val_f1_m: 0.4355 - val_precision_m: 124095.1797 - val_recall_m: 0.4484\n",
      "Epoch 25/1000\n",
      "30919/30919 [==============================] - 6s 203us/step - loss: 0.1057 - mae: 0.2087 - acc: 0.7699 - f1_m: 0.3389 - precision_m: 313065.9688 - recall_m: 0.2968 - val_loss: 0.1066 - val_mae: 0.2139 - val_acc: 0.7682 - val_f1_m: 0.3189 - val_precision_m: 289555.3125 - val_recall_m: 0.2784\n",
      "Epoch 26/1000\n",
      "30919/30919 [==============================] - 6s 205us/step - loss: 0.1071 - mae: 0.2103 - acc: 0.7700 - f1_m: 0.3474 - precision_m: 271668.8125 - recall_m: 0.3028 - val_loss: 0.1071 - val_mae: 0.2063 - val_acc: 0.7780 - val_f1_m: 0.2938 - val_precision_m: 382626.7188 - val_recall_m: 0.2416\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30919/30919 [==============================] - 5s 176us/step - loss: 0.1056 - mae: 0.2088 - acc: 0.7689 - f1_m: 0.3462 - precision_m: 300129.3750 - recall_m: 0.3034 - val_loss: 0.1053 - val_mae: 0.1986 - val_acc: 0.7780 - val_f1_m: 0.3192 - val_precision_m: 372285.4375 - val_recall_m: 0.2653\n",
      "Epoch 28/1000\n",
      "30919/30919 [==============================] - 5s 165us/step - loss: 0.1042 - mae: 0.2073 - acc: 0.7690 - f1_m: 0.3459 - precision_m: 245795.6250 - recall_m: 0.3054 - val_loss: 0.1106 - val_mae: 0.2066 - val_acc: 0.7794 - val_f1_m: 0.2803 - val_precision_m: 382626.6875 - val_recall_m: 0.2309\n",
      "Epoch 29/1000\n",
      "30919/30919 [==============================] - 5s 149us/step - loss: 0.1053 - mae: 0.2090 - acc: 0.7695 - f1_m: 0.3465 - precision_m: 266494.1875 - recall_m: 0.3051 - val_loss: 0.1185 - val_mae: 0.2218 - val_acc: 0.7740 - val_f1_m: 0.2863 - val_precision_m: 330920.4062 - val_recall_m: 0.2399\n",
      "Epoch 30/1000\n",
      "30919/30919 [==============================] - 5s 147us/step - loss: 0.1053 - mae: 0.2084 - acc: 0.7707 - f1_m: 0.3360 - precision_m: 250970.2500 - recall_m: 0.2963 - val_loss: 0.1058 - val_mae: 0.2148 - val_acc: 0.7625 - val_f1_m: 0.3418 - val_precision_m: 268872.8125 - val_recall_m: 0.3062\n",
      "Epoch 31/1000\n",
      "30919/30919 [==============================] - 4s 139us/step - loss: 0.1052 - mae: 0.2091 - acc: 0.7708 - f1_m: 0.3422 - precision_m: 235446.3281 - recall_m: 0.3032 - val_loss: 0.1043 - val_mae: 0.2056 - val_acc: 0.7631 - val_f1_m: 0.3649 - val_precision_m: 186142.7500 - val_recall_m: 0.3344\n",
      "Epoch 32/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.1056 - mae: 0.2086 - acc: 0.7714 - f1_m: 0.3417 - precision_m: 222509.7188 - recall_m: 0.3039 - val_loss: 0.1039 - val_mae: 0.2090 - val_acc: 0.7558 - val_f1_m: 0.3665 - val_precision_m: 206825.2969 - val_recall_m: 0.3314\n",
      "Epoch 33/1000\n",
      "30919/30919 [==============================] - 4s 139us/step - loss: 0.1047 - mae: 0.2084 - acc: 0.7713 - f1_m: 0.3489 - precision_m: 292367.4062 - recall_m: 0.3081 - val_loss: 0.1030 - val_mae: 0.2093 - val_acc: 0.7691 - val_f1_m: 0.3240 - val_precision_m: 217166.5312 - val_recall_m: 0.2858\n",
      "Epoch 34/1000\n",
      "30919/30919 [==============================] - 4s 143us/step - loss: 0.1055 - mae: 0.2092 - acc: 0.7719 - f1_m: 0.3386 - precision_m: 245795.5938 - recall_m: 0.2981 - val_loss: 0.1081 - val_mae: 0.2067 - val_acc: 0.7787 - val_f1_m: 0.2882 - val_precision_m: 279214.0938 - val_recall_m: 0.2438\n",
      "Epoch 35/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.1054 - mae: 0.2086 - acc: 0.7707 - f1_m: 0.3335 - precision_m: 279430.7812 - recall_m: 0.2929 - val_loss: 0.1168 - val_mae: 0.2187 - val_acc: 0.7811 - val_f1_m: 0.2764 - val_precision_m: 268872.8750 - val_recall_m: 0.2267\n",
      "Epoch 36/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.1060 - mae: 0.2081 - acc: 0.7719 - f1_m: 0.3394 - precision_m: 292367.4062 - recall_m: 0.2911 - val_loss: 0.1050 - val_mae: 0.2127 - val_acc: 0.7558 - val_f1_m: 0.3620 - val_precision_m: 206825.2969 - val_recall_m: 0.3326\n",
      "Epoch 37/1000\n",
      "30919/30919 [==============================] - 4s 138us/step - loss: 0.1061 - mae: 0.2091 - acc: 0.7717 - f1_m: 0.3351 - precision_m: 243208.2812 - recall_m: 0.2936 - val_loss: 0.1161 - val_mae: 0.2000 - val_acc: 0.7845 - val_f1_m: 0.2531 - val_precision_m: 196483.9844 - val_recall_m: 0.2092\n",
      "Epoch 38/1000\n",
      "30919/30919 [==============================] - 4s 141us/step - loss: 0.1053 - mae: 0.2075 - acc: 0.7715 - f1_m: 0.3322 - precision_m: 274256.1562 - recall_m: 0.2914 - val_loss: 0.1013 - val_mae: 0.2058 - val_acc: 0.7777 - val_f1_m: 0.3132 - val_precision_m: 320579.1250 - val_recall_m: 0.2615\n",
      "Epoch 39/1000\n",
      "30919/30919 [==============================] - 4s 141us/step - loss: 0.1050 - mae: 0.2069 - acc: 0.7712 - f1_m: 0.3415 - precision_m: 323415.2500 - recall_m: 0.2974 - val_loss: 0.1048 - val_mae: 0.2133 - val_acc: 0.7525 - val_f1_m: 0.3762 - val_precision_m: 144777.7188 - val_recall_m: 0.3545\n",
      "Epoch 40/1000\n",
      "30919/30919 [==============================] - 4s 144us/step - loss: 0.1047 - mae: 0.2074 - acc: 0.7708 - f1_m: 0.3332 - precision_m: 240620.9531 - recall_m: 0.2936 - val_loss: 0.1000 - val_mae: 0.2047 - val_acc: 0.7763 - val_f1_m: 0.3446 - val_precision_m: 382626.6875 - val_recall_m: 0.2887\n",
      "Epoch 41/1000\n",
      "30919/30919 [==============================] - 4s 145us/step - loss: 0.1040 - mae: 0.2070 - acc: 0.7725 - f1_m: 0.3466 - precision_m: 323415.2500 - recall_m: 0.3028 - val_loss: 0.1045 - val_mae: 0.1929 - val_acc: 0.7836 - val_f1_m: 0.2926 - val_precision_m: 299896.5938 - val_recall_m: 0.2453\n",
      "Epoch 42/1000\n",
      "30919/30919 [==============================] - 4s 139us/step - loss: 0.1040 - mae: 0.2066 - acc: 0.7727 - f1_m: 0.3389 - precision_m: 271668.8438 - recall_m: 0.2958 - val_loss: 0.1032 - val_mae: 0.2044 - val_acc: 0.7750 - val_f1_m: 0.3344 - val_precision_m: 341261.6250 - val_recall_m: 0.2837\n",
      "Epoch 43/1000\n",
      "30919/30919 [==============================] - 4s 138us/step - loss: 0.1035 - mae: 0.2059 - acc: 0.7729 - f1_m: 0.3371 - precision_m: 230271.6719 - recall_m: 0.2964 - val_loss: 0.1083 - val_mae: 0.2141 - val_acc: 0.7523 - val_f1_m: 0.3759 - val_precision_m: 206825.2656 - val_recall_m: 0.3431\n",
      "Epoch 44/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.1029 - mae: 0.2057 - acc: 0.7731 - f1_m: 0.3400 - precision_m: 269081.5000 - recall_m: 0.2968 - val_loss: 0.1027 - val_mae: 0.2028 - val_acc: 0.7679 - val_f1_m: 0.3526 - val_precision_m: 320579.1562 - val_recall_m: 0.3070\n",
      "Epoch 45/1000\n",
      "30919/30919 [==============================] - 4s 145us/step - loss: 0.1016 - mae: 0.2045 - acc: 0.7727 - f1_m: 0.3386 - precision_m: 287192.7500 - recall_m: 0.2958 - val_loss: 0.1031 - val_mae: 0.2000 - val_acc: 0.7801 - val_f1_m: 0.3152 - val_precision_m: 465356.8125 - val_recall_m: 0.2570\n",
      "Epoch 46/1000\n",
      "30919/30919 [==============================] - 4s 144us/step - loss: 0.1026 - mae: 0.2056 - acc: 0.7723 - f1_m: 0.3454 - precision_m: 282018.1250 - recall_m: 0.3047 - val_loss: 0.1035 - val_mae: 0.2192 - val_acc: 0.7555 - val_f1_m: 0.3894 - val_precision_m: 289555.3125 - val_recall_m: 0.3570\n",
      "Epoch 47/1000\n",
      "30919/30919 [==============================] - 5s 147us/step - loss: 0.1024 - mae: 0.2047 - acc: 0.7724 - f1_m: 0.3448 - precision_m: 289780.0625 - recall_m: 0.3025 - val_loss: 0.1118 - val_mae: 0.2314 - val_acc: 0.7383 - val_f1_m: 0.4163 - val_precision_m: 196484.0312 - val_recall_m: 0.4016\n",
      "Epoch 48/1000\n",
      "30919/30919 [==============================] - 5s 167us/step - loss: 0.1017 - mae: 0.2045 - acc: 0.7729 - f1_m: 0.3465 - precision_m: 227684.3594 - recall_m: 0.3051 - val_loss: 0.1048 - val_mae: 0.1999 - val_acc: 0.7818 - val_f1_m: 0.3008 - val_precision_m: 341261.6250 - val_recall_m: 0.2532\n",
      "Epoch 49/1000\n",
      "30919/30919 [==============================] - 5s 170us/step - loss: 0.1019 - mae: 0.2047 - acc: 0.7728 - f1_m: 0.3429 - precision_m: 212160.4375 - recall_m: 0.3027 - val_loss: 0.1053 - val_mae: 0.1970 - val_acc: 0.7849 - val_f1_m: 0.2914 - val_precision_m: 403309.2500 - val_recall_m: 0.2323\n",
      "Epoch 50/1000\n",
      "30919/30919 [==============================] - 5s 159us/step - loss: 0.1008 - mae: 0.2038 - acc: 0.7744 - f1_m: 0.3453 - precision_m: 253557.5625 - recall_m: 0.3036 - val_loss: 0.1042 - val_mae: 0.1955 - val_acc: 0.7717 - val_f1_m: 0.3239 - val_precision_m: 268872.8438 - val_recall_m: 0.2769\n",
      "Epoch 51/1000\n",
      "30919/30919 [==============================] - 5s 153us/step - loss: 0.1003 - mae: 0.2026 - acc: 0.7723 - f1_m: 0.3497 - precision_m: 245795.6250 - recall_m: 0.3076 - val_loss: 0.0963 - val_mae: 0.2058 - val_acc: 0.7740 - val_f1_m: 0.3369 - val_precision_m: 310237.8750 - val_recall_m: 0.2855\n",
      "Epoch 52/1000\n",
      "30919/30919 [==============================] - 5s 170us/step - loss: 0.1002 - mae: 0.2034 - acc: 0.7731 - f1_m: 0.3561 - precision_m: 263906.8750 - recall_m: 0.3129 - val_loss: 0.1017 - val_mae: 0.1941 - val_acc: 0.7812 - val_f1_m: 0.3221 - val_precision_m: 310237.8438 - val_recall_m: 0.2709\n",
      "Epoch 53/1000\n",
      "30919/30919 [==============================] - 5s 176us/step - loss: 0.1007 - mae: 0.2032 - acc: 0.7730 - f1_m: 0.3471 - precision_m: 243208.2812 - recall_m: 0.3044 - val_loss: 0.1015 - val_mae: 0.2001 - val_acc: 0.7744 - val_f1_m: 0.3187 - val_precision_m: 268872.8438 - val_recall_m: 0.2755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "30919/30919 [==============================] - 4s 145us/step - loss: 0.1006 - mae: 0.2032 - acc: 0.7741 - f1_m: 0.3450 - precision_m: 263906.8438 - recall_m: 0.3023 - val_loss: 0.1000 - val_mae: 0.2155 - val_acc: 0.7618 - val_f1_m: 0.3905 - val_precision_m: 237849.0312 - val_recall_m: 0.3508\n",
      "Epoch 55/1000\n",
      "30919/30919 [==============================] - 4s 138us/step - loss: 0.1008 - mae: 0.2041 - acc: 0.7731 - f1_m: 0.3493 - precision_m: 282018.1250 - recall_m: 0.3070 - val_loss: 0.1033 - val_mae: 0.2042 - val_acc: 0.7624 - val_f1_m: 0.3637 - val_precision_m: 310237.8750 - val_recall_m: 0.3211\n",
      "Epoch 56/1000\n",
      "30919/30919 [==============================] - 4s 142us/step - loss: 0.1004 - mae: 0.2028 - acc: 0.7745 - f1_m: 0.3501 - precision_m: 263906.8750 - recall_m: 0.3090 - val_loss: 0.0990 - val_mae: 0.2051 - val_acc: 0.7589 - val_f1_m: 0.3812 - val_precision_m: 268872.8438 - val_recall_m: 0.3431\n",
      "Epoch 57/1000\n",
      "30919/30919 [==============================] - 4s 139us/step - loss: 0.1003 - mae: 0.2029 - acc: 0.7738 - f1_m: 0.3497 - precision_m: 250970.2500 - recall_m: 0.3083 - val_loss: 0.1002 - val_mae: 0.1969 - val_acc: 0.7718 - val_f1_m: 0.3720 - val_precision_m: 423991.7188 - val_recall_m: 0.3144\n",
      "Epoch 58/1000\n",
      "30919/30919 [==============================] - 4s 137us/step - loss: 0.1004 - mae: 0.2038 - acc: 0.7743 - f1_m: 0.3515 - precision_m: 240620.9531 - recall_m: 0.3092 - val_loss: 0.0975 - val_mae: 0.1973 - val_acc: 0.7819 - val_f1_m: 0.3084 - val_precision_m: 372285.4375 - val_recall_m: 0.2513\n",
      "Epoch 59/1000\n",
      "30919/30919 [==============================] - 4s 138us/step - loss: 0.1009 - mae: 0.2039 - acc: 0.7736 - f1_m: 0.3421 - precision_m: 240620.9531 - recall_m: 0.3006 - val_loss: 0.1030 - val_mae: 0.2208 - val_acc: 0.7471 - val_f1_m: 0.4029 - val_precision_m: 134436.5156 - val_recall_m: 0.3824\n",
      "Epoch 60/1000\n",
      "30919/30919 [==============================] - 4s 138us/step - loss: 0.1010 - mae: 0.2042 - acc: 0.7733 - f1_m: 0.3377 - precision_m: 230271.6719 - recall_m: 0.2976 - val_loss: 0.1021 - val_mae: 0.1974 - val_acc: 0.7768 - val_f1_m: 0.3203 - val_precision_m: 330920.3750 - val_recall_m: 0.2702\n",
      "Epoch 61/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.0997 - mae: 0.2032 - acc: 0.7727 - f1_m: 0.3579 - precision_m: 250970.2500 - recall_m: 0.3172 - val_loss: 0.1076 - val_mae: 0.1947 - val_acc: 0.7841 - val_f1_m: 0.2852 - val_precision_m: 299896.5938 - val_recall_m: 0.2348\n",
      "Epoch 62/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.0998 - mae: 0.2035 - acc: 0.7745 - f1_m: 0.3476 - precision_m: 253557.5781 - recall_m: 0.3023 - val_loss: 0.1063 - val_mae: 0.2088 - val_acc: 0.7692 - val_f1_m: 0.3209 - val_precision_m: 382626.6875 - val_recall_m: 0.2680\n",
      "Epoch 63/1000\n",
      "30919/30919 [==============================] - 4s 141us/step - loss: 0.0999 - mae: 0.2028 - acc: 0.7741 - f1_m: 0.3565 - precision_m: 269081.5000 - recall_m: 0.3131 - val_loss: 0.0960 - val_mae: 0.1945 - val_acc: 0.7798 - val_f1_m: 0.3203 - val_precision_m: 196483.9844 - val_recall_m: 0.2730\n",
      "Epoch 64/1000\n",
      "30919/30919 [==============================] - 5s 161us/step - loss: 0.0996 - mae: 0.2036 - acc: 0.7738 - f1_m: 0.3548 - precision_m: 256144.8906 - recall_m: 0.3123 - val_loss: 0.0950 - val_mae: 0.1971 - val_acc: 0.7784 - val_f1_m: 0.3296 - val_precision_m: 268872.8438 - val_recall_m: 0.2817\n",
      "Epoch 65/1000\n",
      "30919/30919 [==============================] - 4s 145us/step - loss: 0.1001 - mae: 0.2032 - acc: 0.7722 - f1_m: 0.3540 - precision_m: 276843.4688 - recall_m: 0.3124 - val_loss: 0.0982 - val_mae: 0.1919 - val_acc: 0.7789 - val_f1_m: 0.3323 - val_precision_m: 341261.6562 - val_recall_m: 0.2806\n",
      "Epoch 66/1000\n",
      "30919/30919 [==============================] - 4s 142us/step - loss: 0.1002 - mae: 0.2040 - acc: 0.7737 - f1_m: 0.3481 - precision_m: 232858.9844 - recall_m: 0.3065 - val_loss: 0.0968 - val_mae: 0.2035 - val_acc: 0.7669 - val_f1_m: 0.3682 - val_precision_m: 217166.5312 - val_recall_m: 0.3239\n",
      "Epoch 67/1000\n",
      "30919/30919 [==============================] - 5s 147us/step - loss: 0.0997 - mae: 0.2040 - acc: 0.7749 - f1_m: 0.3493 - precision_m: 258732.2344 - recall_m: 0.3042 - val_loss: 0.1021 - val_mae: 0.2039 - val_acc: 0.7639 - val_f1_m: 0.3732 - val_precision_m: 227507.7812 - val_recall_m: 0.3363\n",
      "Epoch 68/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.0998 - mae: 0.2041 - acc: 0.7730 - f1_m: 0.3451 - precision_m: 250970.2500 - recall_m: 0.3035 - val_loss: 0.1057 - val_mae: 0.2007 - val_acc: 0.7842 - val_f1_m: 0.3047 - val_precision_m: 444674.2812 - val_recall_m: 0.2431\n",
      "Epoch 69/1000\n",
      "30919/30919 [==============================] - 4s 139us/step - loss: 0.1004 - mae: 0.2042 - acc: 0.7736 - f1_m: 0.3432 - precision_m: 235446.3125 - recall_m: 0.3018 - val_loss: 0.0943 - val_mae: 0.2071 - val_acc: 0.7726 - val_f1_m: 0.3458 - val_precision_m: 258531.5469 - val_recall_m: 0.3048\n",
      "Epoch 70/1000\n",
      "30919/30919 [==============================] - 4s 137us/step - loss: 0.1005 - mae: 0.2054 - acc: 0.7744 - f1_m: 0.3445 - precision_m: 232858.9844 - recall_m: 0.3029 - val_loss: 0.0948 - val_mae: 0.1995 - val_acc: 0.7741 - val_f1_m: 0.3555 - val_precision_m: 289555.3125 - val_recall_m: 0.3065\n",
      "Epoch 71/1000\n",
      "30919/30919 [==============================] - 4s 142us/step - loss: 0.1006 - mae: 0.2057 - acc: 0.7737 - f1_m: 0.3442 - precision_m: 222509.7031 - recall_m: 0.3014 - val_loss: 0.0988 - val_mae: 0.1982 - val_acc: 0.7761 - val_f1_m: 0.3356 - val_precision_m: 248190.3125 - val_recall_m: 0.2883\n",
      "Epoch 72/1000\n",
      "30919/30919 [==============================] - 4s 144us/step - loss: 0.1007 - mae: 0.2055 - acc: 0.7751 - f1_m: 0.3453 - precision_m: 269081.5000 - recall_m: 0.3014 - val_loss: 0.0946 - val_mae: 0.1967 - val_acc: 0.7750 - val_f1_m: 0.3686 - val_precision_m: 382626.6875 - val_recall_m: 0.3140\n",
      "Epoch 73/1000\n",
      "30919/30919 [==============================] - 4s 144us/step - loss: 0.1012 - mae: 0.2061 - acc: 0.7744 - f1_m: 0.3532 - precision_m: 248382.9375 - recall_m: 0.3082 - val_loss: 0.1019 - val_mae: 0.2159 - val_acc: 0.7695 - val_f1_m: 0.3418 - val_precision_m: 206825.2344 - val_recall_m: 0.3005\n",
      "Epoch 74/1000\n",
      "30919/30919 [==============================] - 4s 139us/step - loss: 0.1000 - mae: 0.2051 - acc: 0.7745 - f1_m: 0.3464 - precision_m: 214747.7500 - recall_m: 0.3037 - val_loss: 0.0947 - val_mae: 0.2024 - val_acc: 0.7680 - val_f1_m: 0.3748 - val_precision_m: 237849.0625 - val_recall_m: 0.3319\n",
      "Epoch 75/1000\n",
      "30919/30919 [==============================] - 4s 138us/step - loss: 0.1006 - mae: 0.2062 - acc: 0.7747 - f1_m: 0.3511 - precision_m: 271668.8125 - recall_m: 0.3063 - val_loss: 0.1074 - val_mae: 0.1925 - val_acc: 0.7843 - val_f1_m: 0.2774 - val_precision_m: 341261.6250 - val_recall_m: 0.2267\n",
      "Epoch 76/1000\n",
      "30919/30919 [==============================] - 4s 138us/step - loss: 0.1015 - mae: 0.2063 - acc: 0.7748 - f1_m: 0.3517 - precision_m: 266494.1875 - recall_m: 0.3072 - val_loss: 0.1149 - val_mae: 0.2596 - val_acc: 0.7351 - val_f1_m: 0.4097 - val_precision_m: 124095.3359 - val_recall_m: 0.4032\n",
      "Epoch 77/1000\n",
      "30919/30919 [==============================] - 4s 138us/step - loss: 0.1005 - mae: 0.2063 - acc: 0.7743 - f1_m: 0.3406 - precision_m: 232858.9844 - recall_m: 0.3010 - val_loss: 0.0995 - val_mae: 0.2102 - val_acc: 0.7816 - val_f1_m: 0.3113 - val_precision_m: 341261.6250 - val_recall_m: 0.2643\n",
      "Epoch 78/1000\n",
      "30919/30919 [==============================] - 4s 143us/step - loss: 0.1011 - mae: 0.2057 - acc: 0.7738 - f1_m: 0.3499 - precision_m: 245795.6250 - recall_m: 0.3066 - val_loss: 0.1015 - val_mae: 0.1941 - val_acc: 0.7845 - val_f1_m: 0.2920 - val_precision_m: 320579.1562 - val_recall_m: 0.2408\n",
      "Epoch 79/1000\n",
      "30919/30919 [==============================] - 4s 142us/step - loss: 0.1010 - mae: 0.2054 - acc: 0.7748 - f1_m: 0.3394 - precision_m: 227684.3438 - recall_m: 0.2979 - val_loss: 0.0972 - val_mae: 0.2075 - val_acc: 0.7775 - val_f1_m: 0.3252 - val_precision_m: 299896.5938 - val_recall_m: 0.2747\n",
      "Epoch 80/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.1012 - mae: 0.2065 - acc: 0.7744 - f1_m: 0.3368 - precision_m: 194049.1562 - recall_m: 0.2989 - val_loss: 0.1134 - val_mae: 0.2336 - val_acc: 0.7364 - val_f1_m: 0.4338 - val_precision_m: 196484.0312 - val_recall_m: 0.4207\n",
      "Epoch 81/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.1002 - mae: 0.2047 - acc: 0.7743 - f1_m: 0.3500 - precision_m: 274256.1562 - recall_m: 0.3011 - val_loss: 0.1144 - val_mae: 0.2325 - val_acc: 0.7259 - val_f1_m: 0.4237 - val_precision_m: 113754.0156 - val_recall_m: 0.4285\n",
      "Epoch 82/1000\n",
      "30919/30919 [==============================] - 4s 138us/step - loss: 0.1005 - mae: 0.2054 - acc: 0.7742 - f1_m: 0.3464 - precision_m: 235446.3125 - recall_m: 0.3062 - val_loss: 0.0973 - val_mae: 0.2068 - val_acc: 0.7807 - val_f1_m: 0.3233 - val_precision_m: 299896.5938 - val_recall_m: 0.2738\n",
      "Epoch 83/1000\n",
      "30919/30919 [==============================] - 4s 139us/step - loss: 0.1008 - mae: 0.2064 - acc: 0.7744 - f1_m: 0.3467 - precision_m: 256144.8906 - recall_m: 0.3040 - val_loss: 0.1016 - val_mae: 0.1899 - val_acc: 0.7856 - val_f1_m: 0.2782 - val_precision_m: 361944.1875 - val_recall_m: 0.2285\n",
      "Epoch 84/1000\n",
      "30919/30919 [==============================] - 4s 141us/step - loss: 0.1003 - mae: 0.2050 - acc: 0.7744 - f1_m: 0.3503 - precision_m: 261319.5312 - recall_m: 0.3067 - val_loss: 0.1026 - val_mae: 0.2006 - val_acc: 0.7820 - val_f1_m: 0.3194 - val_precision_m: 382626.6875 - val_recall_m: 0.2665\n",
      "Epoch 85/1000\n",
      "30919/30919 [==============================] - 4s 139us/step - loss: 0.1008 - mae: 0.2057 - acc: 0.7744 - f1_m: 0.3498 - precision_m: 326002.5938 - recall_m: 0.3046 - val_loss: 0.1041 - val_mae: 0.2088 - val_acc: 0.7754 - val_f1_m: 0.3376 - val_precision_m: 227507.7500 - val_recall_m: 0.2945\n",
      "Epoch 86/1000\n",
      "30919/30919 [==============================] - 4s 141us/step - loss: 0.1010 - mae: 0.2061 - acc: 0.7749 - f1_m: 0.3442 - precision_m: 214747.7344 - recall_m: 0.3057 - val_loss: 0.0978 - val_mae: 0.2134 - val_acc: 0.7717 - val_f1_m: 0.3543 - val_precision_m: 341261.6250 - val_recall_m: 0.3060\n",
      "Epoch 87/1000\n",
      "30919/30919 [==============================] - 4s 142us/step - loss: 0.1003 - mae: 0.2060 - acc: 0.7750 - f1_m: 0.3543 - precision_m: 284605.4375 - recall_m: 0.3075 - val_loss: 0.1058 - val_mae: 0.2061 - val_acc: 0.7763 - val_f1_m: 0.3415 - val_precision_m: 227507.7812 - val_recall_m: 0.2948\n",
      "Epoch 88/1000\n",
      "30919/30919 [==============================] - 4s 141us/step - loss: 0.1011 - mae: 0.2058 - acc: 0.7738 - f1_m: 0.3428 - precision_m: 282018.1250 - recall_m: 0.3019 - val_loss: 0.1010 - val_mae: 0.1967 - val_acc: 0.7793 - val_f1_m: 0.3073 - val_precision_m: 258531.5781 - val_recall_m: 0.2619625 - reca\n",
      "Epoch 89/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.1011 - mae: 0.2065 - acc: 0.7747 - f1_m: 0.3476 - precision_m: 230271.6719 - recall_m: 0.3072 - val_loss: 0.1006 - val_mae: 0.2209 - val_acc: 0.7599 - val_f1_m: 0.3729 - val_precision_m: 206825.2500 - val_recall_m: 0.3379\n",
      "Epoch 90/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.1015 - mae: 0.2060 - acc: 0.7743 - f1_m: 0.3484 - precision_m: 230271.6719 - recall_m: 0.3069 - val_loss: 0.1025 - val_mae: 0.2030 - val_acc: 0.7832 - val_f1_m: 0.3042 - val_precision_m: 341261.6562 - val_recall_m: 0.2482\n",
      "Epoch 91/1000\n",
      "30919/30919 [==============================] - 4s 142us/step - loss: 0.1009 - mae: 0.2060 - acc: 0.7746 - f1_m: 0.3413 - precision_m: 243208.2812 - recall_m: 0.2986 - val_loss: 0.1026 - val_mae: 0.2156 - val_acc: 0.7777 - val_f1_m: 0.3264 - val_precision_m: 320579.1562 - val_recall_m: 0.2739\n",
      "Epoch 92/1000\n",
      "30919/30919 [==============================] - 4s 142us/step - loss: 0.1011 - mae: 0.2069 - acc: 0.7748 - f1_m: 0.3475 - precision_m: 282018.1250 - recall_m: 0.3014 - val_loss: 0.1028 - val_mae: 0.1899 - val_acc: 0.7856 - val_f1_m: 0.2797 - val_precision_m: 289555.3438 - val_recall_m: 0.2299\n",
      "Epoch 93/1000\n",
      "30919/30919 [==============================] - 4s 141us/step - loss: 0.1010 - mae: 0.2056 - acc: 0.7745 - f1_m: 0.3508 - precision_m: 240620.9531 - recall_m: 0.3072 - val_loss: 0.1071 - val_mae: 0.2360 - val_acc: 0.7718 - val_f1_m: 0.3471 - val_precision_m: 330920.3750 - val_recall_m: 0.2962\n",
      "Epoch 94/1000\n",
      "30919/30919 [==============================] - 4s 146us/step - loss: 0.1011 - mae: 0.2062 - acc: 0.7752 - f1_m: 0.3444 - precision_m: 243208.2812 - recall_m: 0.3022 - val_loss: 0.1088 - val_mae: 0.2071 - val_acc: 0.7868 - val_f1_m: 0.2518 - val_precision_m: 372285.4062 - val_recall_m: 0.1994\n",
      "Epoch 95/1000\n",
      "30919/30919 [==============================] - 4s 144us/step - loss: 0.1012 - mae: 0.2061 - acc: 0.7752 - f1_m: 0.3480 - precision_m: 271668.8125 - recall_m: 0.3045 - val_loss: 0.0989 - val_mae: 0.1882 - val_acc: 0.7810 - val_f1_m: 0.3196 - val_precision_m: 341261.6562 - val_recall_m: 0.2668\n",
      "Epoch 96/1000\n",
      "30919/30919 [==============================] - 4s 139us/step - loss: 0.1021 - mae: 0.2076 - acc: 0.7734 - f1_m: 0.3437 - precision_m: 294954.7188 - recall_m: 0.2982 - val_loss: 0.1100 - val_mae: 0.2216 - val_acc: 0.7510 - val_f1_m: 0.4230 - val_precision_m: 186142.7031 - val_recall_m: 0.3997\n",
      "Epoch 97/1000\n",
      "30919/30919 [==============================] - 4s 139us/step - loss: 0.1014 - mae: 0.2074 - acc: 0.7738 - f1_m: 0.3444 - precision_m: 279430.7812 - recall_m: 0.2999 - val_loss: 0.1020 - val_mae: 0.1924 - val_acc: 0.7865 - val_f1_m: 0.2767 - val_precision_m: 289555.3438 - val_recall_m: 0.2264\n",
      "Epoch 98/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.1016 - mae: 0.2077 - acc: 0.7741 - f1_m: 0.3524 - precision_m: 307891.3438 - recall_m: 0.3041 - val_loss: 0.1059 - val_mae: 0.2132 - val_acc: 0.7665 - val_f1_m: 0.3328 - val_precision_m: 320579.1562 - val_recall_m: 0.2831\n",
      "Epoch 99/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.1017 - mae: 0.2067 - acc: 0.7739 - f1_m: 0.3475 - precision_m: 279430.7812 - recall_m: 0.3032 - val_loss: 0.1033 - val_mae: 0.2213 - val_acc: 0.7594 - val_f1_m: 0.3798 - val_precision_m: 258531.5938 - val_recall_m: 0.3441\n",
      "Epoch 100/1000\n",
      "30919/30919 [==============================] - 4s 143us/step - loss: 0.1009 - mae: 0.2059 - acc: 0.7732 - f1_m: 0.3480 - precision_m: 266494.1875 - recall_m: 0.3029 - val_loss: 0.1102 - val_mae: 0.2059 - val_acc: 0.7828 - val_f1_m: 0.2906 - val_precision_m: 434333.0000 - val_recall_m: 0.2313\n",
      "Epoch 101/1000\n",
      "30919/30919 [==============================] - 4s 139us/step - loss: 0.1002 - mae: 0.2057 - acc: 0.7738 - f1_m: 0.3500 - precision_m: 238033.6406 - recall_m: 0.3097 - val_loss: 0.0980 - val_mae: 0.2076 - val_acc: 0.7749 - val_f1_m: 0.3237 - val_precision_m: 258531.5469 - val_recall_m: 0.2776\n",
      "Epoch 102/1000\n",
      "30919/30919 [==============================] - 4s 139us/step - loss: 0.1003 - mae: 0.2056 - acc: 0.7740 - f1_m: 0.3521 - precision_m: 269081.5000 - recall_m: 0.3071 - val_loss: 0.0981 - val_mae: 0.1945 - val_acc: 0.7796 - val_f1_m: 0.3084 - val_precision_m: 227507.7500 - val_recall_m: 0.2665\n",
      "Epoch 103/1000\n",
      "30919/30919 [==============================] - 4s 140us/step - loss: 0.1011 - mae: 0.2061 - acc: 0.7749 - f1_m: 0.3420 - precision_m: 250970.2500 - recall_m: 0.2999 - val_loss: 0.1022 - val_mae: 0.2094 - val_acc: 0.7753 - val_f1_m: 0.3102 - val_precision_m: 320579.1562 - val_recall_m: 0.2583\n",
      "Epoch 104/1000\n",
      "30919/30919 [==============================] - 4s 141us/step - loss: 0.1014 - mae: 0.2064 - acc: 0.7740 - f1_m: 0.3487 - precision_m: 248382.9375 - recall_m: 0.3050 - val_loss: 0.1053 - val_mae: 0.2213 - val_acc: 0.7508 - val_f1_m: 0.3994 - val_precision_m: 175801.4844 - val_recall_m: 0.3803\n",
      "끝\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "input_var = ['소로', '중로2류', '소로1류', '소로3류', '중로3류', '소로2류', '중로1류', '광로2류', 'old_place', 'child_place', 'crosswork', 'building', 'bus', 'bohang']\n",
    "target_var = ['accident']\n",
    "\n",
    "# 훈련변수 , 종속변수 먼저 나누기\n",
    "train_val, target_val = train2[input_var], train2[target_var]\n",
    "\n",
    "# train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_val, target_val, test_size=0.2, \n",
    "                                                    shuffle=True, random_state=7)\n",
    "\n",
    "print('train : ', X_train.shape, Y_train.shape)\n",
    "print('test : ', X_test.shape, Y_test.shape)\n",
    "\n",
    "X_train, Y_train = np.array(X_train), np.array(Y_train)\n",
    "X_test, Y_test = np.array(X_test), np.array(Y_test)\n",
    "Y_train = np.log1p(Y_train)\n",
    "Y_test = np.log1p(Y_test)\n",
    "\n",
    "model11 = models.Sequential()\n",
    "model11.add(layers.Dense(64, activation='relu'))\n",
    "model11.add(layers.Dense(64, activation='relu'))\n",
    "model11.add(layers.Dense(1))\n",
    "model11.compile(optimizer='rmsprop', loss='mean_squared_error', metrics = ['mae', 'acc', f1_m, precision_m, recall_m])\n",
    "\n",
    "# 학습 - earlystopping Y\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience = 35) # 조기종료 콜백함수 정의\n",
    "hist = model11.fit(X_train, Y_train, epochs=1000, validation_split = 0.2, batch_size = 8, callbacks=[early_stopping]) \n",
    "print('끝')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6053063143353782\n",
      "acuuracy: 0.7456416487693787\n",
      "f1_score: 0.617465615272522\n",
      "precision: 0.5976917147636414\n",
      "recall: 0.6907227039337158\n"
     ]
    }
   ],
   "source": [
    "# model -> epoch 10 / validation_split 0.2 / batch_size 0.8 / layer.dense(64, 2개)\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test, Y_test, verbose=2)\n",
    "\n",
    "print('loss:', loss)\n",
    "print('acuuracy:', accuracy)\n",
    "print('f1_score:', f1_score)\n",
    "print('precision:', precision)\n",
    "print('recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.45077558562710895\n",
      "mae: 0.5555362178607789\n",
      "loss: 0.392409086227417\n",
      "acuuracy: 0.7802982330322266\n",
      "f1_score: 0.6386856436729431\n",
      "precision: 0.7388295531272888\n",
      "recall: 0.6041015386581421\n"
     ]
    }
   ],
   "source": [
    "x_predict = X_test\n",
    "y_predict = model10.predict(x_predict)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(Y_test, y_predict)\n",
    "print('R2 : ', r2)\n",
    "\n",
    "# model -> epoch 10 / validation_split 0.2 / batch_size 0.8 / layer.dense(64, 2개)\n",
    "mae, loss, accuracy, f1_score, precision, recall = model10.evaluate(X_test, Y_test, verbose=2)\n",
    "print('mae:', mae)\n",
    "print('loss:', loss)\n",
    "print('acuuracy:', accuracy)\n",
    "print('f1_score:', f1_score)\n",
    "print('precision:', precision)\n",
    "print('recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.48789924864647005\n",
      "mae: 0.45009913424656994\n",
      "loss: 0.42792753583030596\n",
      "acuuracy: 0.7852633756892005\n",
      "f1_score: 0.6480453597096618\n",
      "precision: 99348.81502606357\n",
      "recall: 0.5915824541465277\n"
     ]
    }
   ],
   "source": [
    "# earlystopping = 20 / epoch 59 / layer.dense(64, 3개)\n",
    "x_predict = X_test\n",
    "y_predict = model2.predict(x_predict)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(Y_test, y_predict)\n",
    "print('R2 : ', r2)\n",
    "\n",
    "# model -> epoch 10 / validation_split 0.2 / batch_size 0.8 / layer.dense(64, 2개)\n",
    "mae, loss, accuracy, f1_score, precision, recall = model2.evaluate(X_test, Y_test, verbose=2)\n",
    "print('mae:', mae)\n",
    "print('loss:', loss)\n",
    "print('acuuracy:', accuracy)\n",
    "print('f1_score:', f1_score)\n",
    "print('precision:', precision)\n",
    "print('recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.30647490447735715\n",
      "mae: 0.6095578639413288\n",
      "loss: 0.440673897293652\n",
      "acuuracy: 0.7469729896807145\n",
      "f1_score: 0.5954909688331173\n",
      "precision: 0.620184624884719\n",
      "recall: 0.6196657133919105\n"
     ]
    }
   ],
   "source": [
    "# earlystopping = 50 / epoch 169 / layer.dense(64, 3개)\n",
    "x_predict = X_test\n",
    "y_predict = model3.predict(x_predict)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(Y_test, y_predict)\n",
    "print('R2 : ', r2)\n",
    "\n",
    "mae, loss, accuracy, f1_score, precision, recall = model3.evaluate(X_test, Y_test, verbose=2)\n",
    "print('mae:', mae)\n",
    "print('loss:', loss)\n",
    "print('acuuracy:', accuracy)\n",
    "print('f1_score:', f1_score)\n",
    "print('precision:', precision)\n",
    "print('recall:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.5136699248642669\n",
      "loss: 0.37498908043894646\n",
      "acuuracy: 0.7657042326584719\n"
     ]
    }
   ],
   "source": [
    "# earlystopping = 35 / epoch 114 / layer.dense(64, 2개)\n",
    "x_predict = X_test\n",
    "y_predict = model5.predict(x_predict)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(Y_test, y_predict)\n",
    "print('R2 : ', r2)\n",
    "\n",
    "mae, loss, accuracy, f1_score, precision, recall = model5.evaluate(X_test, Y_test, verbose=2)\n",
    "print('loss:', loss)\n",
    "print('acuuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.5160198565212558\n",
      "loss: 0.3885853992946447\n",
      "acuuracy: 0.8034771810181945\n"
     ]
    }
   ],
   "source": [
    "# earlystopping = 35 / epoch 170 / layer.dense(64, 3개)\n",
    "x_predict = X_test\n",
    "y_predict = model4.predict(x_predict)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(Y_test, y_predict)\n",
    "print('R2 : ', r2)\n",
    "\n",
    "mae, loss, accuracy, f1_score, precision, recall = model4.evaluate(X_test, Y_test, verbose=2)\n",
    "print('loss:', loss)\n",
    "print('acuuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.5397395995191425\n",
      "loss: 0.4008658953696492\n",
      "acuuracy: 0.7951981786379814\n"
     ]
    }
   ],
   "source": [
    "# earlystopping = 35 / epoch 115 / layer.dense(64, 4개)\n",
    "x_predict = X_test\n",
    "y_predict = model6.predict(x_predict)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(Y_test, y_predict)\n",
    "print('R2 : ', r2)\n",
    "\n",
    "mae, loss, accuracy, f1_score, precision, recall = model6.evaluate(X_test, Y_test, verbose=2)\n",
    "print('loss:', loss)\n",
    "print('acuuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.5438737336963582\n",
      "loss: 0.40115870284784977\n",
      "acuuracy: 0.7680844458489515\n"
     ]
    }
   ],
   "source": [
    "# earlystopping = 35 / epoch 119 / layer.dense(64, 5개)\n",
    "x_predict = X_test\n",
    "y_predict = model7.predict(x_predict)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(Y_test, y_predict)\n",
    "print('R2 : ', r2)\n",
    "\n",
    "mae, loss, accuracy, f1_score, precision, recall = model7.evaluate(X_test, Y_test, verbose=2)\n",
    "print('loss:', loss)\n",
    "print('acuuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.4034768475463365\n",
      "loss: 0.19983325898647308\n",
      "acuuracy: 0.7569078207015991\n"
     ]
    }
   ],
   "source": [
    "# earlystopping = 35 / epoch 97 / layer.dense(64, 3개)\n",
    "x_predict = X_test\n",
    "y_predict = model10.predict(x_predict)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(Y_test, y_predict)\n",
    "print('R2 : ', r2)\n",
    "\n",
    "mae, loss, accuracy, f1_score, precision, recall = model10.evaluate(X_test, Y_test, verbose=2)\n",
    "print('loss:', loss)\n",
    "print('acuuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  0.37633725898957604\n",
      "loss: 0.22460684180259705\n",
      "acuuracy: 0.7562868595123291\n"
     ]
    }
   ],
   "source": [
    "# earlystopping = 35 / epoch 97 / layer.dense(64, 5개)\n",
    "x_predict = X_test\n",
    "y_predict = model11.predict(x_predict)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(Y_test, y_predict)\n",
    "print('R2 : ', r2)\n",
    "\n",
    "mae, loss, accuracy, f1_score, precision, recall = model11.evaluate(X_test, Y_test, verbose=2)\n",
    "print('loss:', loss)\n",
    "print('acuuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
